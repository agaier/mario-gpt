{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db35712-44f4-4e69-9589-67a5cdab7f5d",
   "metadata": {},
   "source": [
    "## Load Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc50c35e-0dbe-4ffd-993d-280b28d4ce8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from mario_gpt import MarioDataset, MarioLM, TrainingConfig, MarioGPTTrainer\n",
    "from mario_gpt.utils import view_level, convert_level_to_png, join_list_of_list, characterize\n",
    "from mario_gpt.flower_level import FLOWER_LEVEL\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4693bf8d-9703-40ee-9024-6a9bfb57df25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ../FlowerGPT lm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaiera/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/transformers-4.27.3-py3.9.egg/transformers/models/auto/modeling_auto.py:1295: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ../FlowerGPT tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14000 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---\n",
    "# load model and generate flowers\n",
    "#---\n",
    "img_length = 30\n",
    "\n",
    "mario_lm = MarioLM(lm_path=\"../FlowerGPT\", tokenizer_path=\"../FlowerGPT\")\n",
    "dataset = MarioDataset(mario_lm.tokenizer, level_string=FLOWER_LEVEL) # for token conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eeef84b-7131-4894-902a-c7f00049c2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_to_rgb(token_array, token_dict, colors=None):\n",
    "    # Create a reverse dictionary mapping token values to keys\n",
    "    reverse_token_dict = {int(v.item()): k for k, v in token_dict.items()}\n",
    "\n",
    "    # Use ascending integers as colors if not provided\n",
    "    if colors is None:\n",
    "        colors = [\n",
    "            [0, 170, 0],       \n",
    "            [185, 122, 87],      \n",
    "            [255, 242, 0],     \n",
    "            [191, 232, 242],   \n",
    "        ]        \n",
    "\n",
    "    # Create a dictionary mapping token values to colors\n",
    "    color_dict = {token_value: color for token_value, color in zip(reverse_token_dict.keys(), colors)}\n",
    "\n",
    "    # Function to map token values to colors or red if not in token_dict\n",
    "    def map_to_color(token_value):\n",
    "        return color_dict.get(token_value, [255, 0, 0])\n",
    "\n",
    "    # Create a 3D array of RGB colors based on the token_array and color_dict using nested list comprehension\n",
    "    rgb_array = np.array([[[map_to_color(token_value) for token_value in row] for row in token_array]])\n",
    "\n",
    "    return rgb_array\n",
    "\n",
    "def generated_to_rgb(generated_level):\n",
    "    A = generated_level.level_tensor\n",
    "    rot_img = np.rot90(A.reshape(img_length,14))\n",
    "    return token_to_rgb(rot_img, dataset.token_dict)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54b3733-1c32-44dc-9df2-909844c8f07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [\" \"]\n",
    "generated_level = mario_lm.sample(\n",
    "    prompts=prompts,\n",
    "    num_steps=(14*img_length),\n",
    "    temperature=1.0,\n",
    "    use_tqdm=True\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5a4f411-e379-4f08-8d33-7528efb3d79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd61c0e33d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Flowers\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "image = generated_to_rgb(generated_level)\n",
    "ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119176a-f8ea-4d25-9be5-df880814f472",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c365983-10a0-4d12-9229-bb81d349757a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mario_gpt.flower_metric import count_flowers, calculate_crookedness_score\n",
    "\n",
    "# Prompts\n",
    "prompt_flower = [\"no\", \"few\", \"some\", \"many\"]\n",
    "prompt_straight = [\"not\", \"kinda\", \"very\", \"totally\"]\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "# Generate\n",
    "prompts = [f\"{prompt_flower[i]} flowers, {prompt_straight[j]} straight\"]\n",
    "generated_level = mario_lm.sample(\n",
    "    prompts=prompts,\n",
    "    num_steps=(14*img_length),\n",
    "    temperature=1.0,\n",
    "    use_tqdm=True\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "\n",
    "# Test\n",
    "image = generated_to_rgb(generated_level)\n",
    "n_flowers = count_flowers(image)\n",
    "straightness = calculate_crookedness_score(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49f0abaf-6886-4421-9686-9ef87ff57914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Flowers: 2, Straightness: 151')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Measure Result\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "image = generated_to_rgb(generated_level)\n",
    "ax.imshow(image)\n",
    "n_flowers = count_flowers(image)\n",
    "straightness = calculate_crookedness_score(image)\n",
    "ax.set_title(f'Flowers: {n_flowers}, Straightness: {straightness}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16158e-e7d7-4aca-9aae-69864b03af7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Levels and Test as Line Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "acfbc3f1-cab9-4da5-bc49-9e6bb87d75f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([1, 7]), torch.Size([1, 8]) first: 56, last: 36:   1%|▊                                                                                                   | 6/700 [00:00<00:12, 56.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([1, 513]), torch.Size([1, 514]) first: 56, last: 36:  73%|████████████████████████████████████████████████████████████████████▉                         | 513/700 [00:30<00:11, 16.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Generate\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_flower[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m flowers, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_straight[j]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m straight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m     generated_level \u001b[38;5;241m=\u001b[39m \u001b[43mmario_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimg_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     clear_output()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Test\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/NZB/mario-gpt/mario_gpt/lm/gpt.py:87\u001b[0m, in \u001b[0;36mMarioGPT.sample\u001b[0;34m(self, seed, prompts, num_steps, temperature, encoder_hidden_states, use_tqdm, return_tensor, height)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     77\u001b[0m     seed: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     height: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m,\n\u001b[1;32m     85\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleOutput:\n\u001b[1;32m     86\u001b[0m     sampler \u001b[38;5;241m=\u001b[39m GPTSampler(\u001b[38;5;28mself\u001b[39m, temperature, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_len, use_tqdm)\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/NZB/mario-gpt/mario_gpt/sampler.py:265\u001b[0m, in \u001b[0;36mGPTSampler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/NZB/mario-gpt/mario_gpt/sampler.py:240\u001b[0m, in \u001b[0;36mGPTSampler.sample\u001b[0;34m(self, seed, prompts, num_steps, encoder_hidden_states, return_tensor, height)\u001b[0m\n\u001b[1;32m    238\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m context_len \u001b[38;5;241m+\u001b[39m diff\n\u001b[1;32m    239\u001b[0m     inp \u001b[38;5;241m=\u001b[39m inp[:, \u001b[38;5;241m-\u001b[39mctx:] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 240\u001b[0m next_tokens, encoder_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m out_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    245\u001b[0m     [out_tensor, next_tokens\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    246\u001b[0m )\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_tqdm:\n",
      "File \u001b[0;32m~/Code/NZB/mario-gpt/mario_gpt/sampler.py:160\u001b[0m, in \u001b[0;36mGPTSampler.step\u001b[0;34m(self, seed, encoder_hidden_states)\u001b[0m\n\u001b[1;32m    158\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(seed)\u001b[38;5;241m.\u001b[39mto(seed\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    159\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m seed\n\u001b[0;32m--> 160\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmario_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/transformers-4.27.3-py3.9.egg/transformers/models/gpt2/modeling_gpt2.py:1075\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1075\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/transformers-4.27.3-py3.9.egg/transformers/models/gpt2/modeling_gpt2.py:899\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    889\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    890\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    891\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    896\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    897\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/transformers-4.27.3-py3.9.egg/transformers/models/gpt2/modeling_gpt2.py:411\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    409\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    410\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_cross_attn(hidden_states)\n\u001b[0;32m--> 411\u001b[0m cross_attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m cross_attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/transformers-4.27.3-py3.9.egg/transformers/models/gpt2/modeling_gpt2.py:308\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf class is used as cross attention, the weights `q_attn` have to be defined. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure to instantiate class with `GPT2Attention(..., is_cross_attention=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    307\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_attn(hidden_states)\n\u001b[0;32m--> 308\u001b[0m     key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nzb-gpt/lib/python3.9/site-packages/torch/_tensor.py:802\u001b[0m, in \u001b[0;36mTensor.split\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(split_size, (\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mSymInt)):\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_VF\u001b[38;5;241m.\u001b[39msplit_with_sizes(\u001b[38;5;28mself\u001b[39m, split_size, dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompts\n",
    "prompt_flower = [\"no\", \"few\", \"some\", \"many\"]\n",
    "prompt_straight = [\"not\", \"kinda\", \"very\", \"totally\"]\n",
    "\n",
    "n_rows = len(prompt_flower)\n",
    "n_cols = len(prompt_straight)\n",
    "n_iterations = 5\n",
    "img_length = 50  # Set this to the desired image length\n",
    "\n",
    "# Initialize lists to store scores for each iteration\n",
    "flower_scores_iter = [[[] for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "straight_scores_iter = [[[] for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "\n",
    "# Generate and Test\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        for k in range(n_iterations):\n",
    "            # Generate\n",
    "            prompts = [f\"{prompt_flower[i]} flowers, {prompt_straight[j]} straight\"]\n",
    "            generated_level = mario_lm.sample(\n",
    "                prompts=prompts,\n",
    "                num_steps=14*img_length,\n",
    "                temperature=1.0,\n",
    "                use_tqdm=True\n",
    "            )\n",
    "            clear_output()\n",
    "\n",
    "            # Test\n",
    "            image = generated_to_rgb(generated_level)\n",
    "            n_flowers = count_flowers(image)\n",
    "            straightness = calculate_crookedness_score(image)\n",
    "\n",
    "            # Append scores to lists\n",
    "            flower_scores_iter[i][j].append(n_flowers)\n",
    "            straight_scores_iter[i][j].append(straightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb843b-3190-4127-8833-5ff5523a35a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display Box Plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# Flower Scores\n",
    "\n",
    "# Flower Scores\n",
    "flower_data = [np.array(flower_scores_iter)[:, j, :].flatten() for j in range(n_cols)]\n",
    "bp = ax[0].boxplot(flower_data)\n",
    "ax[0].set_title(\"Number of Flowers\")\n",
    "ax[0].set_xlabel(\"Straightness\")\n",
    "ax[0].set_xticks(range(1, n_cols + 1))\n",
    "ax[0].set_xticklabels(prompt_flower)\n",
    "ax[0].set_ylabel(\"Flowers\")\n",
    "\n",
    "# Straightness Scores\n",
    "straight_data = [np.array(straight_scores_iter)[:, j, :].flatten() for j in range(n_cols)]\n",
    "bp = ax[1].boxplot(straight_data)\n",
    "ax[1].set_title(\"Straightness\")\n",
    "ax[1].set_xlabel(\"Straightness\")\n",
    "ax[1].set_xticks(range(1, n_cols + 1))\n",
    "ax[1].set_xticklabels(prompt_straight)\n",
    "ax[1].set_ylabel(\"Straightness Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43a859-5368-4ea6-9542-0574c1aee6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display Heatmaps\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.heatmap(flower_scores, annot=True, fmt=\".2f\", ax=ax[0], xticklabels=prompt_straight, yticklabels=prompt_flower, cmap=\"YlGnBu\")\n",
    "ax[0].set_title(\"Number of Flowers\")\n",
    "ax[0].set_xlabel(\"Straightness\")\n",
    "ax[0].set_ylabel(\"Flowers\")\n",
    "\n",
    "sns.heatmap(straight_scores, annot=True, fmt=\".2f\", ax=ax[1], xticklabels=prompt_straight, yticklabels=prompt_flower, cmap=\"YlGnBu\")\n",
    "ax[1].set_title(\"Straightness Scores\")\n",
    "ax[1].set_xlabel(\"Straightness\")\n",
    "ax[1].set_ylabel(\"Flowers\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a68adfe-bcd5-487f-ac7d-35ef2cebf122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
